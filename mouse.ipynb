{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "##训练集 3000样本\n",
    "train_df = pd.read_csv(\"dsjtzs_txfz_training.txt\",header=None,delim_whitespace=True)\n",
    "train_df.columns = [\"id\",\"points_str\",\"target_point\",\"label\"]\n",
    "##\n",
    "\n",
    "\n",
    "## 预测集10000样本\n",
    "predict_df = pd.read_csv(\"dsjtzs_txfz_test1.txt\",header=None,delim_whitespace=True)\n",
    "predict_df.columns = [\"id\",\"points_str\",\"target_point\"]\n",
    "##\n",
    "\n",
    "train_df.set_index([\"id\"],inplace=True)\n",
    "\n",
    "def f(s):\n",
    "    s =str(s)\n",
    "    return s[0:-1]\n",
    "train_df[\"points_str\"]= train_df[\"points_str\"].apply(f)\n",
    "\n",
    "\n",
    "def  point_sort(x,y):\n",
    "    if (x[2]>y[2]):\n",
    "        return 1\n",
    "    elif (x[2]<y[2]):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "def f(t):\n",
    "    s=str(t[\"points_str\"])\n",
    "    splited=s.split(\";\")\n",
    "    ret = []\n",
    "    for item in splited:\n",
    "        item_splited = item.split(\",\")\n",
    "        item_tuple = ( int(item_splited[0]),  int(item_splited[1]) ,int(item_splited[2]) )\n",
    "        ret.append(item_tuple)\n",
    "    sorted_arr = sorted(ret,point_sort)\n",
    "    return sorted_arr\n",
    "train_df[\"points_sorted_list\"]=train_df[[\"points_str\"]].apply(f,axis=1)\n",
    "\n",
    "def f(s):\n",
    "    sorted_arr=s[\"points_sorted_list\"]\n",
    "    _sum_x =0 \n",
    "    _sum_y=0 \n",
    "    _count =0\n",
    "    ret=[]\n",
    "    for i in range(0,len(sorted_arr)-1):\n",
    "        if (sorted_arr[i][2]!=sorted_arr[i+1][2]):\n",
    "                if _count==0:\n",
    "                    ret.append(sorted_arr[i])\n",
    "                else:\n",
    "                    _count +=1\n",
    "                    _sum_x+=sorted_arr[i][0]\n",
    "                    _sum_y+=sorted_arr[i][1]\n",
    "                    average_x =float( _sum_x ) / _count\n",
    "                    average_y =float(_sum_y)/_count\n",
    "                    ret.append((average_x,average_y,sorted_arr[i][2]))\n",
    "                    _count =0\n",
    "                    _sum_x=0\n",
    "                    _sum_y=0\n",
    "        else: \n",
    "            _sum_x += sorted_arr[i][0]\n",
    "            _sum_y+=sorted_arr[i][1]\n",
    "            _count+=1\n",
    "    \n",
    "    index = len(sorted_arr)-1\n",
    "    if (sorted_arr[index][2] == sorted_arr[index-1][2]):\n",
    "        _count+=1\n",
    "        _sum_x+=sorted_arr[index][0]\n",
    "        _sum_y+=sorted_arr[index][1]\n",
    "        average_x =float( _sum_x ) / _count\n",
    "        average_y =float(_sum_y)/_count\n",
    "        ret.append((average_x,average_y,sorted_arr[index][2]))\n",
    "    else:\n",
    "        ret.append(sorted_arr[index])\n",
    "    return ret\n",
    "\n",
    "train_df[\"points_diff_time_list\"]=train_df[[\"points_sorted_list\"]].apply(f,axis=1)\n",
    "\n",
    "# print train_df.loc[1,\"points_str\"]\n",
    "# print \"-----\"\n",
    "# print train_df.loc[1,\"points_sorted_list\"]\n",
    "\n",
    "# points 都有数据\n",
    "#print pd.isnull(train_df[\"points\"]).value_counts()\n",
    "\n",
    "# 2600 个1 正例；400个0 负例 (id:2601-3000)\n",
    "#train_df.label.value_counts()\n",
    "\n",
    "# id 都是不同的\n",
    "#train_df.id.value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "## 预测集10000样本\n",
    "predict_df = pd.read_csv(\"dsjtzs_txfz_test1.txt\",header=None,delim_whitespace=True)\n",
    "predict_df.columns = [\"id\",\"points_str\",\"target_point\"]\n",
    "##\n",
    "\n",
    "predict_df.set_index([\"id\"],inplace=True)\n",
    "\n",
    "def f(s):\n",
    "    s =str(s)\n",
    "    return s[0:-1]\n",
    "predict_df[\"points_str\"]= predict_df[\"points_str\"].apply(f)\n",
    "\n",
    "\n",
    "def  point_sort(x,y):\n",
    "    if (x[2]>y[2]):\n",
    "        return 1\n",
    "    elif (x[2]<y[2]):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "def f(t):\n",
    "    s=str(t[\"points_str\"])\n",
    "    splited=s.split(\";\")\n",
    "    ret = []\n",
    "    for item in splited:\n",
    "        item_splited = item.split(\",\")\n",
    "        item_tuple = ( int(item_splited[0]),  int(item_splited[1]) ,int(item_splited[2]) )\n",
    "        ret.append(item_tuple)\n",
    "    sorted_arr = sorted(ret,point_sort)\n",
    "    return sorted_arr\n",
    "predict_df[\"points_sorted_list\"]=predict_df[[\"points_str\"]].apply(f,axis=1)\n",
    "\n",
    "def f(s):\n",
    "    sorted_arr=s[\"points_sorted_list\"]\n",
    "    _sum_x =0 \n",
    "    _sum_y=0 \n",
    "    _count =0\n",
    "    ret=[]\n",
    "    for i in range(0,len(sorted_arr)-1):\n",
    "        if (sorted_arr[i][2]!=sorted_arr[i+1][2]):\n",
    "                if _count==0:\n",
    "                    ret.append(sorted_arr[i])\n",
    "                else:\n",
    "                    _count +=1\n",
    "                    _sum_x+=sorted_arr[i][0]\n",
    "                    _sum_y+=sorted_arr[i][1]\n",
    "                    average_x =float( _sum_x ) / _count\n",
    "                    average_y =float(_sum_y)/_count\n",
    "                    ret.append((average_x,average_y,sorted_arr[i][2]))\n",
    "                    _count =0\n",
    "                    _sum_x=0\n",
    "                    _sum_y=0\n",
    "        else: \n",
    "            _sum_x += sorted_arr[i][0]\n",
    "            _sum_y+=sorted_arr[i][1]\n",
    "            _count+=1\n",
    "    \n",
    "    index = len(sorted_arr)-1\n",
    "    if (sorted_arr[index][2] == sorted_arr[index-1][2]):\n",
    "        _count+=1\n",
    "        _sum_x+=sorted_arr[index][0]\n",
    "        _sum_y+=sorted_arr[index][1]\n",
    "        average_x =float( _sum_x ) / _count\n",
    "        average_y =float(_sum_y)/_count\n",
    "        ret.append((average_x,average_y,sorted_arr[index][2]))\n",
    "    else:\n",
    "        ret.append(sorted_arr[index])\n",
    "    return ret\n",
    "\n",
    "predict_df[\"points_diff_time_list\"]=predict_df[[\"points_sorted_list\"]].apply(f,axis=1)\n",
    "\n",
    "# print train_df.loc[1,\"points_str\"]\n",
    "# print \"-----\"\n",
    "# print train_df.loc[1,\"points_sorted_list\"]\n",
    "\n",
    "# points 都有数据\n",
    "#print pd.isnull(train_df[\"points\"]).value_counts()\n",
    "\n",
    "# 2600 个1 正例；400个0 负例 (id:2601-3000)\n",
    "#train_df.label.value_counts()\n",
    "\n",
    "# id 都是不同的\n",
    "#train_df.id.value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               points_x  \\\n",
      "id                                                        \n",
      "1     [353, 367, 388, 416, 500, 584, 675, 724, 780, ...   \n",
      "2     [283, 290, 297, 304, 311, 325, 339, 346, 360, ...   \n",
      "3     [255, 297, 353, 423, 479, 542, 605, 668, 745, ...   \n",
      "4     [437, 549, 605, 661, 731, 780, 822, 871, 885, ...   \n",
      "5     [248, 255, 297, 339, 451, 577, 717, 885, 948, ...   \n",
      "6     [171, 178, 178, 206, 353, 486, 668, 815, 899, ...   \n",
      "7     [227, 234, 241, 248, 255, 262, 269, 276, 283, ...   \n",
      "8     [199, 241, 255, 283, 339, 395, 465, 493, 507, ...   \n",
      "9     [178, 192, 199, 206, 220, 227, 241, 255, 262, ...   \n",
      "10    [290, 318, 346, 374, 437, 493, 570, 675, 766, ...   \n",
      "11    [269, 262, 262, 262, 283, 304, 346, 402, 563, ...   \n",
      "12    [255, 395, 514, 521, 535, 577, 584, 605, 640, ...   \n",
      "13    [206, 220, 241, 248, 262, 269, 283, 290, 304, ...   \n",
      "14    [297, 325, 374, 423, 458, 514, 528, 570, 612, ...   \n",
      "15    [227, 234, 241, 255, 276, 318, 360, 409, 437, ...   \n",
      "16    [290, 297, 297, 304, 311, 311, 318, 325, 332, ...   \n",
      "17    [227, 234, 241, 262, 283, 297, 318, 332, 339, ...   \n",
      "18    [248, 255, 269, 283, 297, 304, 318, 332, 346, ...   \n",
      "19    [283, 297, 311, 318, 325, 339, 346, 353, 360, ...   \n",
      "20    [276, 269, 269, 262, 262, 255, 248, 248, 241, ...   \n",
      "21    [213, 213, 220, 227, 234, 241, 248, 255, 262, ...   \n",
      "22    [220, 227, 234, 241, 248, 276, 290, 318, 360, ...   \n",
      "23    [381, 395, 409, 430, 458, 486, 521, 549, 584, ...   \n",
      "24    [332, 430, 458, 479, 514, 556, 619, 640, 675, ...   \n",
      "25    [360, 388, 409, 430, 451, 472, 500, 521, 535, ...   \n",
      "26    [255, 262, 269, 276, 283, 290, 297, 304, 311, ...   \n",
      "27    [248, 255, 269, 276, 304, 325, 332, 339, 346, ...   \n",
      "28    [213, 241, 290, 353, 402, 472, 549, 647, 724, ...   \n",
      "29    [178, 234, 297, 367, 430, 493, 556, 612, 668, ...   \n",
      "30    [297, 311, 346, 381, 423, 556, 633, 822, 976, ...   \n",
      "...                                                 ...   \n",
      "2971  [248, 283, 297, 339, 346, 388, 437, 500, 577, ...   \n",
      "2972  [332, 381, 423, 465, 493, 507, 549, 626, 696, ...   \n",
      "2973  [255, 318, 388, 409, 437, 479, 500, 542, 591, ...   \n",
      "2974  [269, 325, 367, 409, 444, 507, 535, 563, 619, ...   \n",
      "2975  [304, 339, 367, 374, 423, 493, 528, 549, 626, ...   \n",
      "2976  [304, 325, 367, 437, 486, 500, 535, 591, 605, ...   \n",
      "2977  [276, 290, 311, 360, 374, 381, 388, 423, 458, ...   \n",
      "2978  [339, 360, 409, 444, 458, 528, 570, 605, 654, ...   \n",
      "2979  [339, 367, 374, 409, 430, 444, 500, 528, 542, ...   \n",
      "2980  [262, 276, 290, 360, 430, 472, 500, 507, 535, ...   \n",
      "2981  [234, 248, 318, 339, 381, 430, 465, 479, 535, ...   \n",
      "2982  [304, 311, 339, 395, 402, 430, 458, 521, 591, ...   \n",
      "2983  [325, 381, 458, 479, 528, 570, 640, 703, 745, ...   \n",
      "2984  [297, 311, 346, 381, 437, 486, 528, 556, 591, ...   \n",
      "2985  [269, 311, 346, 367, 395, 402, 444, 472, 528, ...   \n",
      "2986  [276, 290, 311, 360, 374, 409, 444, 521, 528, ...   \n",
      "2987  [255, 283, 353, 423, 479, 493, 549, 598, 647, ...   \n",
      "2988  [283, 304, 339, 367, 409, 486, 500, 556, 633, ...   \n",
      "2989  [255, 297, 325, 374, 416, 430, 486, 507, 521, ...   \n",
      "2990  [318, 367, 402, 444, 458, 472, 500, 542, 605, ...   \n",
      "2991  [332, 395, 465, 528, 591, 605, 647, 661, 668, ...   \n",
      "2992  [325, 339, 353, 381, 430, 437, 500, 521, 570, ...   \n",
      "2993  [248, 283, 304, 346, 388, 465, 493, 528, 570, ...   \n",
      "2994  [332, 409, 444, 486, 535, 577, 591, 619, 682, ...   \n",
      "2995  [255, 276, 346, 381, 444, 465, 528, 535, 556, ...   \n",
      "2996  [297, 346, 395, 402, 465, 528, 570, 647, 661, ...   \n",
      "2997  [255, 311, 332, 360, 416, 486, 528, 549, 591, ...   \n",
      "2998  [262, 276, 346, 409, 486, 563, 577, 626, 696, ...   \n",
      "2999  [283, 346, 402, 444, 458, 500, 570, 584, 591, ...   \n",
      "3000  [241, 276, 297, 360, 423, 465, 514, 542, 619, ...   \n",
      "\n",
      "                                               points_y  \\\n",
      "id                                                        \n",
      "1     [2607, 2607, 2620, 2620, 2620, 2620, 2620, 262...   \n",
      "2     [2490, 2490, 2490, 2490, 2490, 2503, 2503, 250...   \n",
      "3     [2503, 2503, 2529, 2542, 2555, 2568, 2581, 260...   \n",
      "4     [2724, 2711, 2724, 2750, 2789, 2802, 2828, 284...   \n",
      "5     [2542, 2542, 2542, 2555, 2568, 2594, 2633, 265...   \n",
      "6     [2685, 2685, 2672, 2659, 2594, 2594, 2594, 259...   \n",
      "7     [2464, 2464, 2464, 2464, 2464, 2464, 2464, 246...   \n",
      "8     [2516, 2542, 2542, 2542, 2542, 2542, 2542, 254...   \n",
      "9     [2503, 2503, 2503, 2503, 2503, 2503, 2503, 250...   \n",
      "10    [2555, 2555, 2555, 2555, 2555, 2555, 2555, 255...   \n",
      "11    [2490, 2490, 2490, 2490, 2503, 2516, 2529, 254...   \n",
      "12    [2542, 2607, 2607, 2607, 2607, 2594, 2594, 258...   \n",
      "13    [2438, 2438, 2438, 2438, 2438, 2438, 2438, 243...   \n",
      "14    [2581, 2581, 2581, 2581, 2581, 2581, 2581, 258...   \n",
      "15    [2516, 2516, 2516, 2516, 2516, 2516, 2516, 251...   \n",
      "16    [2438, 2425, 2412, 2412, 2412, 2399, 2399, 239...   \n",
      "17    [2568, 2568, 2568, 2542, 2542, 2542, 2529, 252...   \n",
      "18    [2568, 2568, 2568, 2568, 2568, 2568, 2568, 256...   \n",
      "19    [2542, 2542, 2542, 2542, 2542, 2542, 2542, 254...   \n",
      "20    [2555, 2555, 2568, 2581, 2594, 2594, 2594, 260...   \n",
      "21    [2594, 2607, 2607, 2607, 2607, 2607, 2607, 262...   \n",
      "22    [2516, 2516, 2516, 2516, 2516, 2516, 2516, 251...   \n",
      "23    [2555, 2555, 2568, 2568, 2568, 2568, 2581, 258...   \n",
      "24    [2581, 2555, 2555, 2555, 2555, 2555, 2555, 255...   \n",
      "25    [2607, 2607, 2620, 2633, 2633, 2633, 2633, 263...   \n",
      "26    [2555, 2555, 2555, 2555, 2555, 2555, 2555, 255...   \n",
      "27    [2516, 2516, 2516, 2503, 2503, 2503, 2503, 250...   \n",
      "28    [2529, 2529, 2542, 2555, 2555, 2555, 2555, 255...   \n",
      "29    [2529, 2542, 2555, 2555, 2555, 2555, 2568, 259...   \n",
      "30    [2451, 2451, 2477, 2490, 2503, 2555, 2581, 259...   \n",
      "...                                                 ...   \n",
      "2971  [2438, 2464, 2490, 2568, 2633, 2750, 2633, 263...   \n",
      "2972  [2620, 2568, 2672, 2659, 2581, 2568, 2477, 256...   \n",
      "2973  [2581, 2594, 2594, 2594, 2594, 2594, 2594, 271...   \n",
      "2974  [2490, 2568, 2568, 2438, 2568, 2607, 2568, 264...   \n",
      "2975  [2568, 2581, 2620, 2490, 2503, 2555, 2620, 267...   \n",
      "2976  [2516, 2620, 2620, 2620, 2555, 2620, 2620, 275...   \n",
      "2977  [2438, 2568, 2568, 2672, 2568, 2568, 2568, 267...   \n",
      "2978  [2464, 2581, 2724, 2659, 2581, 2581, 2451, 255...   \n",
      "2979  [2451, 2464, 2581, 2620, 2633, 2633, 2633, 263...   \n",
      "2980  [2438, 2503, 2594, 2620, 2737, 2724, 2620, 262...   \n",
      "2981  [2607, 2581, 2568, 2568, 2568, 2568, 2568, 259...   \n",
      "2982  [2633, 2620, 2620, 2659, 2620, 2620, 2555, 262...   \n",
      "2983  [2438, 2464, 2555, 2555, 2451, 2555, 2555, 255...   \n",
      "2984  [2529, 2594, 2594, 2594, 2594, 2594, 2594, 267...   \n",
      "2985  [2542, 2555, 2555, 2555, 2555, 2555, 2555, 255...   \n",
      "2986  [2620, 2607, 2607, 2698, 2607, 2464, 2516, 252...   \n",
      "2987  [2581, 2490, 2581, 2698, 2581, 2581, 2581, 267...   \n",
      "2988  [2568, 2568, 2568, 2568, 2568, 2568, 2503, 252...   \n",
      "2989  [2477, 2555, 2555, 2555, 2646, 2581, 2555, 255...   \n",
      "2990  [2620, 2594, 2594, 2594, 2529, 2594, 2633, 260...   \n",
      "2991  [2607, 2581, 2581, 2659, 2633, 2581, 2581, 258...   \n",
      "2992  [2607, 2594, 2555, 2555, 2555, 2555, 2555, 267...   \n",
      "2993  [2503, 2594, 2620, 2620, 2620, 2477, 2542, 262...   \n",
      "2994  [2529, 2542, 2594, 2711, 2646, 2594, 2594, 267...   \n",
      "2995  [2451, 2516, 2568, 2646, 2646, 2542, 2646, 264...   \n",
      "2996  [2477, 2529, 2594, 2568, 2594, 2477, 2529, 259...   \n",
      "2997  [2490, 2542, 2594, 2737, 2711, 2685, 2659, 263...   \n",
      "2998  [2438, 2503, 2594, 2646, 2698, 2659, 2646, 264...   \n",
      "2999  [2568, 2646, 2568, 2646, 2607, 2646, 2646, 264...   \n",
      "3000  [2594, 2555, 2542, 2555, 2555, 2555, 2555, 268...   \n",
      "\n",
      "                                            points_time  target_point_x  \\\n",
      "id                                                                        \n",
      "1     [349, 376, 418, 442, 493, 547, 592, 643, 694, ...          1420.5   \n",
      "2     [190, 229, 253, 295, 340, 382, 436, 484, 538, ...          1018.0   \n",
      "3     [424, 445, 469, 499, 517, 541, 562, 589, 610, ...           601.5   \n",
      "4     [466, 514, 553, 613, 730, 751, 787, 847, 907, ...           675.0   \n",
      "5     [73, 109, 163, 217, 265, 316, 364, 424, 466, 5...           787.0   \n",
      "6     [229, 277, 301, 346, 400, 448, 505, 550, 604, ...          1049.5   \n",
      "7     [289, 349, 385, 412, 445, 481, 493, 553, 589, ...          1060.0   \n",
      "8     [253, 277, 301, 346, 397, 442, 493, 541, 592, ...           573.5   \n",
      "9     [577, 592, 601, 619, 631, 637, 664, 679, 685, ...           724.0   \n",
      "10    [229, 247, 274, 298, 322, 343, 370, 394, 418, ...          1133.5   \n",
      "11    [94, 133, 139, 184, 229, 259, 277, 301, 358, 3...           556.0   \n",
      "12    [43, 193, 292, 313, 355, 439, 457, 514, 604, 6...           787.0   \n",
      "13    [658, 703, 751, 808, 874, 919, 1093, 1213, 130...           899.0   \n",
      "14    [229, 250, 304, 313, 322, 358, 373, 394, 430, ...          1049.5   \n",
      "15    [229, 250, 283, 331, 364, 412, 466, 514, 565, ...          1263.0   \n",
      "16    [37, 178, 229, 250, 274, 301, 346, 373, 418, 4...           531.5   \n",
      "17    [322, 349, 370, 421, 445, 466, 487, 511, 532, ...          1557.0   \n",
      "18    [1066, 1114, 1138, 1162, 1186, 1213, 1237, 126...           741.5   \n",
      "19    [109, 145, 205, 259, 346, 394, 448, 538, 589, ...          1035.5   \n",
      "20    [172, 196, 220, 226, 295, 298, 310, 358, 370, ...          1091.5   \n",
      "21    [22, 85, 88, 112, 157, 181, 199, 208, 220, 241...          1602.5   \n",
      "22    [172, 340, 364, 388, 412, 439, 463, 481, 505, ...           622.5   \n",
      "23    [445, 469, 496, 517, 541, 568, 598, 619, 640, ...           535.0   \n",
      "24    [109, 325, 358, 487, 508, 541, 556, 586, 637, ...           937.5   \n",
      "25    [436, 478, 520, 571, 622, 673, 727, 775, 817, ...           608.5   \n",
      "26    [370, 376, 406, 424, 442, 448, 463, 484, 487, ...          1214.0   \n",
      "27    [1024, 1054, 1096, 1132, 1183, 1234, 1282, 133...           528.0   \n",
      "28    [229, 253, 274, 301, 325, 352, 370, 397, 421, ...           559.5   \n",
      "29    [484, 490, 529, 535, 577, 586, 622, 631, 670, ...           580.5   \n",
      "30    [442, 508, 568, 610, 649, 721, 763, 838, 889, ...           629.5   \n",
      "...                                                 ...             ...   \n",
      "2971  [205, 2536, 2614, 2638, 5617, 5647, 5719, 8152...           528.0   \n",
      "2972  [910, 3064, 3106, 8806, 8860, 8968, 9049, 1189...           573.5   \n",
      "2973  [985, 3070, 3118, 3166, 3187, 3214, 3316, 3349...           801.0   \n",
      "2974  [688, 2749, 2830, 2929, 2971, 4924, 5026, 5104...          1221.0   \n",
      "2975  [226, 1234, 1291, 1357, 1462, 1513, 1588, 7093...          1214.0   \n",
      "2976  [472, 1600, 1699, 6991, 12850, 16783, 19852, 1...           584.0   \n",
      "2977  [178, 2203, 2311, 2386, 2476, 2509, 2557, 2641...          1035.5   \n",
      "2978  [1030, 1723, 1804, 1852, 1924, 1984, 5395, 542...          1067.0   \n",
      "2979  [721, 2056, 4546, 4615, 4681, 8035, 8140, 8170...          1294.5   \n",
      "2980  [169, 2050, 2080, 2158, 2254, 2302, 2389, 4627...           566.5   \n",
      "2981  [790, 3241, 3337, 3394, 3499, 3553, 3610, 3682...           689.0   \n",
      "2982  [1009, 3190, 9088, 9130, 9208, 9280, 11593, 11...           552.5   \n",
      "2983  [484, 1201, 1276, 1312, 1396, 1501, 1606, 1699...          1123.0   \n",
      "2984  [193, 2251, 6838, 10930, 10951, 15874, 15895, ...           528.0   \n",
      "2985  [217, 2650, 7423, 7513, 7594, 7633, 7669, 7735...           601.5   \n",
      "2986  [856, 2926, 2977, 3040, 3115, 7117, 7186, 1040...           843.0   \n",
      "2987  [718, 2269, 2350, 4237, 6808, 6862, 6952, 1043...           808.0   \n",
      "2988  [862, 3322, 3403, 7615, 7696, 7795, 10957, 110...           927.0   \n",
      "2989  [1060, 1756, 1864, 3868, 3958, 4018, 6814, 685...           615.5   \n",
      "2990  [604, 2176, 2212, 2293, 2380, 2440, 5794, 5854...           650.5   \n",
      "2991  [817, 3403, 7435, 7531, 7582, 7669, 7696, 7789...           535.0   \n",
      "2992  [406, 1741, 7477, 7531, 7552, 11683, 11734, 11...          1109.0   \n",
      "2993  [514, 2071, 2146, 5698, 5773, 5833, 5866, 5893...           832.5   \n",
      "2994  [1015, 3643, 3703, 9124, 11320, 11395, 14497, ...          1588.5   \n",
      "2995  [844, 1750, 1804, 1906, 1987, 2050, 2137, 2194...           748.5   \n",
      "2996  [577, 1369, 1390, 1495, 1555, 1621, 1717, 1798...           734.5   \n",
      "2997  [841, 2836, 2872, 8215, 8275, 8311, 8419, 8479...          1280.5   \n",
      "2998  [598, 2107, 2203, 6820, 6847, 12604, 12631, 12...          1021.5   \n",
      "2999  [202, 1414, 1441, 1465, 1567, 4846, 4915, 9217...          1091.5   \n",
      "3000  [904, 2527, 2593, 5284, 5335, 7978, 8038, 1355...          1574.5   \n",
      "\n",
      "      target_point_y   target_point  \n",
      "id                                   \n",
      "1              202.0     1420.5,202  \n",
      "2              189.0     1018.0,189  \n",
      "3              559.5    601.5,559.5  \n",
      "4              202.0      675.0,202  \n",
      "5              189.0      787.0,189  \n",
      "6             1313.5  1049.5,1313.5  \n",
      "7              748.0     1060.0,748  \n",
      "8              189.0      573.5,189  \n",
      "9              189.0      724.0,189  \n",
      "10             189.0     1133.5,189  \n",
      "11             189.0      556.0,189  \n",
      "12             371.0      787.0,371  \n",
      "13             189.0      899.0,189  \n",
      "14             189.0     1049.5,189  \n",
      "15             189.0     1263.0,189  \n",
      "16             189.0      531.5,189  \n",
      "17             189.0     1557.0,189  \n",
      "18             202.0      741.5,202  \n",
      "19             241.0     1035.5,241  \n",
      "20             189.0     1091.5,189  \n",
      "21            1079.5  1602.5,1079.5  \n",
      "22             202.0      622.5,202  \n",
      "23             202.0      535.0,202  \n",
      "24             299.5    937.5,299.5  \n",
      "25             189.0      608.5,189  \n",
      "26             189.0     1214.0,189  \n",
      "27            1313.5   528.0,1313.5  \n",
      "28            1372.0     559.5,1372  \n",
      "29            1190.0     580.5,1190  \n",
      "30             189.0      629.5,189  \n",
      "...              ...            ...  \n",
      "2971           436.0      528.0,436  \n",
      "2972          1235.5   573.5,1235.5  \n",
      "2973           371.0      801.0,371  \n",
      "2974           241.0     1221.0,241  \n",
      "2975           189.0     1214.0,189  \n",
      "2976           189.0      584.0,189  \n",
      "2977           605.0     1035.5,605  \n",
      "2978          1287.5  1067.0,1287.5  \n",
      "2979           189.0     1294.5,189  \n",
      "2980          1339.5   566.5,1339.5  \n",
      "2981          1112.0     689.0,1112  \n",
      "2982          1372.0     552.5,1372  \n",
      "2983           195.5   1123.0,195.5  \n",
      "2984           670.0      528.0,670  \n",
      "2985           358.0      601.5,358  \n",
      "2986           189.0      843.0,189  \n",
      "2987           202.0      808.0,202  \n",
      "2988           189.0      927.0,189  \n",
      "2989           189.0      615.5,189  \n",
      "2990           189.0      650.5,189  \n",
      "2991           189.0      535.0,189  \n",
      "2992           189.0     1109.0,189  \n",
      "2993           514.0      832.5,514  \n",
      "2994           189.0     1588.5,189  \n",
      "2995           189.0      748.5,189  \n",
      "2996          1073.0     734.5,1073  \n",
      "2997           189.0     1280.5,189  \n",
      "2998           371.0     1021.5,371  \n",
      "2999           221.5   1091.5,221.5  \n",
      "3000           267.0     1574.5,267  \n",
      "\n",
      "[2998 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def f_x(s):\n",
    "     \n",
    "    ret =[]\n",
    "    for item in s:\n",
    "        ret.append(int(item[0]))\n",
    "    return ret\n",
    "        \n",
    "train_df[\"points_x\"]= train_df[\"points_diff_time_list\"].apply(f_x)\n",
    "\n",
    "def f_y (s):\n",
    "     \n",
    "    ret=[]\n",
    "    for item in s:\n",
    "        ret.append(int(item[1]))\n",
    "    return ret\n",
    "train_df[\"points_y\"]=train_df[\"points_diff_time_list\"].apply(f_y)\n",
    "\n",
    "def f_time (s):\n",
    "  \n",
    "    ret=[]\n",
    "    for item in s:\n",
    "        ret.append(int(item[2]) )\n",
    "    return ret\n",
    "train_df[\"points_time\"]=train_df[\"points_diff_time_list\"].apply(f_time)\n",
    "\n",
    "def f_target_point_x(s):\n",
    "    s = str(s)\n",
    "    splited = s.split(\",\")\n",
    "    return float(splited[0])\n",
    "train_df[\"target_point_x\"]=train_df[\"target_point\"].apply(f_target_point_x)\n",
    "\n",
    "def f_target_point_y (s):\n",
    "    s =str(s)\n",
    "    splited =s.split(\",\")\n",
    "    return float(splited[1])\n",
    "train_df[\"target_point_y\"]=train_df[\"target_point\"].apply(f_target_point_y)\n",
    "\n",
    "\n",
    "### 3000条训练数据\n",
    "#train_df =train_df[[\"points_x\",\"points_y\",\"points_time\",\"target_point_x\",\"target_point_y\",\"target_point\",\"label\"]]\n",
    "###\n",
    "\n",
    "###10w条预测集\n",
    "train_df =train_df[[\"points_x\",\"points_y\",\"points_time\",\"target_point_x\",\"target_point_y\",\"target_point\"]]\n",
    "###\n",
    "\n",
    "#去掉points就１个的, id有：493,2019　(points没有２个的，就不用删除２个的了)\n",
    "def filter(s):\n",
    "    if len(s)==1:\n",
    "        return False\n",
    "    return True\n",
    "filters = train_df[\"points_x\"].apply(filter)\n",
    "train_df=train_df[filters]\n",
    "\n",
    "\n",
    "print train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99944, 6)\n"
     ]
    }
   ],
   "source": [
    "def f_x(s):\n",
    "     \n",
    "    ret =[]\n",
    "    for item in s:\n",
    "        ret.append(int(item[0]))\n",
    "    return ret\n",
    "        \n",
    "predict_df[\"points_x\"]= predict_df[\"points_diff_time_list\"].apply(f_x)\n",
    "\n",
    "def f_y (s):\n",
    "     \n",
    "    ret=[]\n",
    "    for item in s:\n",
    "        ret.append(int(item[1]))\n",
    "    return ret\n",
    "predict_df[\"points_y\"]=predict_df[\"points_diff_time_list\"].apply(f_y)\n",
    "\n",
    "def f_time (s):\n",
    "  \n",
    "    ret=[]\n",
    "    for item in s:\n",
    "        ret.append(int(item[2]) )\n",
    "    return ret\n",
    "predict_df[\"points_time\"]=predict_df[\"points_diff_time_list\"].apply(f_time)\n",
    "\n",
    "def f_target_point_x(s):\n",
    "    s = str(s)\n",
    "    splited = s.split(\",\")\n",
    "    return float(splited[0])\n",
    "predict_df[\"target_point_x\"]=predict_df[\"target_point\"].apply(f_target_point_x)\n",
    "\n",
    "def f_target_point_y (s):\n",
    "    s =str(s)\n",
    "    splited =s.split(\",\")\n",
    "    return float(splited[1])\n",
    "predict_df[\"target_point_y\"]=predict_df[\"target_point\"].apply(f_target_point_y)\n",
    "\n",
    "\n",
    "### 3000条训练数据\n",
    "#train_df =train_df[[\"points_x\",\"points_y\",\"points_time\",\"target_point_x\",\"target_point_y\",\"target_point\",\"label\"]]\n",
    "###\n",
    "\n",
    "###10w条预测集\n",
    "predict_df =predict_df[[\"points_x\",\"points_y\",\"points_time\",\"target_point_x\",\"target_point_y\",\"target_point\"]]\n",
    "###\n",
    "\n",
    "#去掉points就１个的, id有：493,2019　(points没有２个的，就不用删除２个的了)\n",
    "def filter(s):\n",
    "    if len(s)==1:\n",
    "        return False\n",
    "    return True\n",
    "filters = predict_df[\"points_x\"].apply(filter)\n",
    "predict_df=predict_df[filters]\n",
    "\n",
    "\n",
    "print predict_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,7),dpi=98)\n",
    "# p1 = plt.subplot(211)\n",
    "# p2 = plt.subplot(212)\n",
    "# x = train_df.loc[1,\"points_x\"]\n",
    "# y  = train_df.loc[1,\"points_y\"]\n",
    "# target_x = train_df.loc[1,\"target_point_x\"]\n",
    "# target_y = train_df.loc[1,\"target_point_y\"]\n",
    "# print x\n",
    "# print y\n",
    "# p1.plot(x,y,'-',color='r',label=\"person\")\n",
    "# p1.plot(target_x,target_y,marker='*')\n",
    "# p1.legend()\n",
    "# plt.show()\n",
    "ids = [25]\n",
    "for id in ids:\n",
    "    plt.figure(id)  #一个Figure对象可以包含多个子图（Axes）．指定了plt.figure(i)之后的操作就是在图表i 下进行的\n",
    "    x = train_df.loc[id,\"points_x\"]\n",
    "    y  = train_df.loc[id,\"points_y\"]\n",
    "    target_x = train_df.loc[id,\"target_point_x\"]\n",
    "    target_y = train_df.loc[id,\"target_point_y\"]\n",
    "#     print x\n",
    "#     print y\n",
    "    print id\n",
    "    print (target_x,target_y)\n",
    "    print \"-----------\"\n",
    "    if train_df.loc[id,\"label\"]==1:\n",
    "        labelStr=\"person\"\n",
    "    else:\n",
    "        labelStr=\"robort\"\n",
    "    plt.scatter(x,y,c=\"r\",marker=\"*\")\n",
    "#  plt.plot(x,y,'-',color='r',label=labelStr)\n",
    "    plt.plot(target_x,target_y,marker='*')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 2, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-92a824d73401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2417\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   3669\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3670\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3671\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3672\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3771\u001b[0m         block = make_block(values=value, ndim=self.ndim,\n\u001b[0;32m-> 3772\u001b[0;31m                            placement=slice(loc, loc + 1))\n\u001b[0m\u001b[1;32m   3773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3774\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   2683\u001b[0m                      placement=placement, dtype=dtype)\n\u001b[1;32m   2684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2685\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m \u001b[0;31m# TODO: flexible with index=None and/or items=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim, fastpath)\u001b[0m\n\u001b[1;32m    107\u001b[0m             raise ValueError('Wrong number of items passed %d, placement '\n\u001b[1;32m    108\u001b[0m                              'implies %d' % (len(self.values),\n\u001b[0;32m--> 109\u001b[0;31m                                              len(self.mgr_locs)))\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 2, placement implies 1"
     ]
    }
   ],
   "source": [
    "test=pd.DataFrame({\"a\":[1,2,3,4],\"b\":[2,3,4,5]})\n",
    "def f(s):\n",
    "    ret =[1,2]\n",
    "    return ret\n",
    "test[\"c\"]=test[[\"a\",\"b\"]].apply(f,axis=1,reduce=None,broadcast=False)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3f2ff75d8458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print tem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m  \u001b[0mf\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tem=train_df[0:1]\n",
    "# print tem\n",
    "\n",
    "def  f (s):\n",
    "\n",
    "    ret = np.array([])\n",
    "    points_x= s[\"points_x\"]\n",
    "    points_time =s[\"points_time\"]\n",
    "    for x in range(1,len(points_x)):\n",
    "        print points_x[x]\n",
    "        velocity = (float(points_x[x])-points_x[x-1])/(float(points_time[x])-points_time[x-1])\n",
    "        np.append(ret,velocity)\n",
    "     \n",
    "    return ret\n",
    "tem[\"velocity_x\"]= tem[[\"points_x\",\"points_time\"]].apply(f,axis=1,reduce=False)\n",
    " \n",
    "\n",
    "# def f(s):\n",
    "#     ret =[]\n",
    "#     points_y = s[\"points_y\"]\n",
    "#     points_time = s[\"points_time\"]\n",
    "#     for x in range(1,len(points_y)):\n",
    "#         velocity = (float(points_y[x])-points_y[x-1])/(float(points_time[x])-points_time[x-1])\n",
    "#         ret.append(velocity)\n",
    "#     return ret\n",
    "# train_df[\"velocity_y\"]=train_df[[\"points_y\",\"points_time\"]].apply(f,axis=1)\n",
    "\n",
    "# def f(s):\n",
    "#     ret =[]\n",
    "#     velocity_x =s[\"velocity_x\"]\n",
    "#     times = s[\"points_time\"]\n",
    "#     if len(velocity_x)>1:\n",
    "#         for x in range (1,len (velocity_x)):\n",
    "#             accelerate_x = (float(velocity_x[x])- velocity_x[x-1])/((float(times[x+1])+times[x])/2 - (float(times[x])+times[x-1])/2)\n",
    "#             ret.append(accelerate_x)\n",
    "#     return ret\n",
    "# train_df[\"accelerate_x\"]=train_df[[\"velocity_x\",\"points_time\"]].apply(f,axis=1)\n",
    "\n",
    "\n",
    "# def f(s):\n",
    "#     ret = []\n",
    "#     velocity_y =s[\"velocity_y\"]\n",
    "#     times=s[\"points_time\"]\n",
    "#     if (len(velocity_y)>1):\n",
    "#         for x in range(1,len(velocity_y)):\n",
    "#             accelerate_y = (float(velocity_y[x])-velocity_y[x-1])/((float(times[x+1])+times[x])/2 - (float(times[x])+times[x-1])/2)\n",
    "#             ret.append(accelerate_y)\n",
    "#     return ret\n",
    "# train_df[\"accelerate_y\"]=train_df[[\"velocity_y\",\"points_time\"]].apply(f,axis=1)\n",
    "# def f(s):\n",
    "#     t = np.array(s[\"velocity_x\"])\n",
    "#     print t\n",
    "#     print t.shape\n",
    " \n",
    "# tem[[\"velocity_x\"]].apply(f,axis=1,reduce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# # 对于point就一个点的，速度就是０\n",
    "# train_df[\"velocity_x\"]=train_df[\"velocity_x\"].apply(lambda x: [0] if (len(x)==0) else x )\n",
    "# train_df[\"velocity_y\"]=train_df[\"velocity_y\"].apply(lambda x: [0] if(len(x)==0) else x)\n",
    "\n",
    "# #对于速度就一个值的，加速度为０\n",
    "# train_df[\"accelerate_x\"]=train_df[\"accelerate_x\"].apply(lambda x: [0] if (len(x)==0) else x)\n",
    "# train_df[\"accelerate_y\"]=train_df[\"accelerate_y\"].apply(lambda x: [0] if (len(x)==0) else x)\n",
    "\n",
    "# points y 的方差，points x 的方差\n",
    "train_df[\"points_y_var\"]=train_df[\"points_y\"].apply(lambda x :np.var(x))\n",
    "train_df[\"points_x_var\"]=train_df[\"points_x\"].apply(lambda x:np.var(x))\n",
    "\n",
    "# 均值：速度　加速度\n",
    "train_df[\"velocity_x_mean\"]=train_df[\"velocity_x\"].apply(lambda x: np.mean(np.array(x)))\n",
    "train_df[\"velocity_y_mean\"]=train_df[\"velocity_y\"].apply(lambda x:np.mean(np.array(x)))\n",
    "train_df[\"accelerate_x_mean\"]=train_df[\"accelerate_x\"].apply(lambda x:np.mean(np.array(x)))\n",
    "train_df[\"accelerate_y_mean\"]=train_df[\"accelerate_y\"] .apply(lambda x:np.mean(np.array(x)))\n",
    "\n",
    "# 方差：速度　加速度\n",
    "train_df[\"velocity_x_var\"]=train_df[\"velocity_x\"].apply(lambda x:np.var(np.array(x)))\n",
    "train_df[\"velocity_y_var\"]=train_df[\"velocity_y\"].apply(lambda x:np.var(np.array(x)))\n",
    "train_df[\"accelerate_x_var\"]=train_df[\"accelerate_x\"].apply(lambda x:np.var(np.array(x)))\n",
    "train_df[\"accelerate_y_var\"]=train_df[\"accelerate_y\"].apply(lambda x:np.var(np.array(x)))\n",
    "\n",
    "# 最大值: 速度 加速度\n",
    "train_df[\"max_velocity_x\"] =train_df[\"velocity_x\"].apply(lambda x: max(x))\n",
    "train_df[\"max_velocity_y\"] = train_df[\"velocity_y\"].apply(lambda x:max(x))\n",
    "train_df[\"max_accelerate_x\"] = train_df[\"accelerate_x\"].apply(lambda x:max(x))\n",
    "train_df[\"max_accelerate_y\"] = train_df[\"accelerate_y\"].apply(lambda x:max(x))\n",
    "\n",
    "# 最小值:速度 加速度\n",
    "train_df[\"min_velocity_x\"]= train_df[\"velocity_x\"].apply(lambda x: min(x))\n",
    "train_df[\"min_velocity_y\"]=train_df[\"velocity_y\"].apply(lambda x:min(x))\n",
    "train_df[\"min_accelerate_x\"]=train_df[\"accelerate_x\"].apply(lambda x:min(x))\n",
    "train_df[\"min_accelerate_y\"]=train_df[\"accelerate_y\"].apply(lambda x:min(x))\n",
    "\n",
    "# count : 速度  (即count:加速度，count:路径中每个点的y 距离目标y的 距离 )\n",
    "train_df[\"count_velocity\"]= train_df[\"velocity_x\"].apply(lambda x: len(x))\n",
    " \n",
    "\n",
    "\n",
    "#25%: 速度　加速度\n",
    "train_df[\"velocity_x_percentile_25\"]=train_df[\"velocity_x\"].apply(lambda x :np.percentile(x,25))\n",
    "train_df[\"velocity_y_percentile_25\"]=train_df[\"velocity_y\"].apply(lambda x:np.percentile(x,25))\n",
    "train_df[\"accelerate_x_percentile_25\"]=train_df[\"accelerate_x\"].apply(lambda x:np.percentile(x,25))\n",
    "train_df[\"accelerate_y_percentile_25\"]=train_df[\"accelerate_y\"].apply(lambda x:np.percentile(x,25))\n",
    "\n",
    "# 75% : 速度　加速度\n",
    "train_df[\"velocity_x_percentile_75\"]=train_df[\"velocity_x\"].apply(lambda x:np.percentile(x,75))\n",
    "train_df[\"velocity_y_percentile_75\"]=train_df[\"velocity_y\"].apply(lambda x:np.percentile(x,75))\n",
    "train_df[\"accelerate_x_percentile_75\"]=train_df[\"accelerate_x\"].apply(lambda x:np.percentile(x,75))\n",
    "train_df[\"accelerate_y_percentile_75\"]=train_df[\"accelerate_y\"].apply(lambda x:np.percentile(x,75))\n",
    "\n",
    "# 50% :速度方差\n",
    "train_df[\"velocity_x_percentile_50\"]=train_df[\"velocity_x\"].apply(lambda x:np.percentile(x,75))\n",
    "train_df[\"velocity_y_percentile_50\"]=train_df[\"velocity_y\"].apply(lambda x:np.percentile(x,75))\n",
    "train_df[\"accelerate_x_percentile_50\"]=train_df[\"accelerate_x\"].apply(lambda x:np.percentile(x,75))\n",
    "train_df[\"accelerate_y_percentile_50\"]=train_df[\"accelerate_y\"].apply(lambda x:np.percentile(x,75))\n",
    "\n",
    "\n",
    "train_df[\"x_mean\"]=train_df[\"points_x\"].apply(lambda x:np.mean(np.array(x)))\n",
    "train_df[\"y_mean\"]=train_df[\"points_y\"].apply(lambda x:np.mean(np.array(x)))\n",
    "\n",
    "# 路径中x 的平均值距离目标x的距离\n",
    "def f(s):\n",
    "    x_mean =s[\"x_mean\"]\n",
    "    target_point_x = s[\"target_point_x\"]\n",
    "    return x_mean-target_point_x\n",
    "train_df[\"x_mean_dis_target_x\"] = train_df[[\"x_mean\",\"target_point_x\"]].apply(f,axis=1)\n",
    "\n",
    "# 路径中　y的平均值距离目标y的距离　\n",
    "def f(s):\n",
    "    y_mean =s[\"y_mean\"]\n",
    "    target_point_y = s[\"target_point_y\"]\n",
    "    return y_mean - target_point_y\n",
    "train_df[\"y_mean_dis_target_y\"]=train_df[[\"y_mean\",\"target_point_y\"]].apply(f,axis=1)\n",
    "\n",
    "# 路径中每个点的x 距离目标x 的距离　（数组）\n",
    "def f(s):\n",
    "    points_x = s[\"points_x\"]\n",
    "    target_point_x =s[\"target_point_x\"]\n",
    "    ret=[]\n",
    "    for i in range(0,len(points_x)):\n",
    "        ret.append(points_x[i]-target_point_x)\n",
    "    return ret\n",
    "train_df[\"x_dis_target_point_x\"]=train_df[[\"points_x\",\"target_point_x\"]].apply(f,axis=1)\n",
    "\n",
    "# 路径中点x 距离目标x 的最小距离，最大距离，等比分点，平均,方差\n",
    "train_df[\"x_dis_target_point_x_min\"]=train_df.x_dis_target_point_x.apply(lambda x:min(x))\n",
    "train_df[\"x_dis_target_point_x_max\"]=train_df.x_dis_target_point_x.apply(lambda x:max(x))\n",
    "train_df[\"x_dis_target_point_x_25\"]=train_df.x_dis_target_point_x.apply(lambda x: np.percentile(x,25))\n",
    "train_df[\"x_dis_target_point_x_50\"]=train_df.x_dis_target_point_x.apply(lambda x:np.percentile(x,50))\n",
    "train_df[\"x_dis_target_point_x_75\"]=train_df.x_dis_target_point_x.apply(lambda x:np.percentile(x,75))\n",
    "train_df[\"x_dis_target_point_x_average\"]=train_df.x_dis_target_point_x.apply(lambda x:np.mean(x))\n",
    "train_df[\"x_dis_target_point_x_var\"]=train_df.x_dis_target_point_x.apply(lambda x:np.var(x))\n",
    "\n",
    "# 路径中每个点的y 距离目标y的 距离 （数组）\n",
    "def f(s):\n",
    "    points_y = s[\"points_y\"]\n",
    "    target_point_y = s[\"target_point_y\"]\n",
    "    ret = []\n",
    "    for i in range(0,len(points_y)):\n",
    "        ret.append(points_y[i]-target_point_y)\n",
    "    return ret\n",
    "train_df[\"y_dis_target_point_y\"]=train_df[[\"points_y\",\"target_point_y\"]].apply(f,axis=1)\n",
    "\n",
    "# 路径中点y 距离目标y 的最小距离，最大距离，等比分点，平均,方差\n",
    "train_df[\"y_dis_target_point_y_min\"]=train_df.y_dis_target_point_y.apply(lambda x:min(x))\n",
    "train_df[\"y_dis_target_point_y_max\"]=train_df.y_dis_target_point_y.apply(lambda x:max(x))\n",
    "train_df[\"y_dis_target_point_y_25\"]=train_df.y_dis_target_point_y.apply(lambda x: np.percentile(x,25))\n",
    "train_df[\"y_dis_target_point_y_50\"]=train_df.y_dis_target_point_y.apply(lambda x:np.percentile(x,50))\n",
    "train_df[\"y_dis_target_point_x_75\"]=train_df.y_dis_target_point_y.apply(lambda x:np.percentile(x,75))\n",
    "train_df[\"y_dis_target_point_y_average\"]=train_df.y_dis_target_point_y.apply(lambda x:np.mean(x))\n",
    "train_df[\"y_dis_target_point_y_var\"]=train_df.y_dis_target_point_y.apply(lambda x:np.var(x))\n",
    "\n",
    "# y 突变的次数 (台阶个数)\n",
    "def f(s):\n",
    "    ret =0\n",
    "    for i in range(1,len(s)):\n",
    "        if abs(s[i]-s[i-1])>=2:\n",
    "            ret+=1\n",
    "    return ret\n",
    "train_df[\"y_diff_count\"]=train_df[\"points_y\"].apply(f)\n",
    "\n",
    "# x多少个不变（每个台阶的长度,数组）\n",
    "def f(s):\n",
    "    ret = []\n",
    "    count =1\n",
    "    for i  in range(1,len(s)):\n",
    "        if(s[i]==s[i-1]):\n",
    "            count+=1\n",
    "        else:\n",
    "            ret.append(count)\n",
    "            count=1\n",
    "    ret.append(count)\n",
    "\n",
    "    return ret\n",
    "    \n",
    "train_df[\"x_phases_length\"]=train_df[\"points_y\"].apply(f)\n",
    "\n",
    "# x_phases_length 的min max,25,50,75, mean,var,count\n",
    "train_df[\"x_phase_length_min\"]=train_df[\"x_phases_length\"].apply(lambda x:min(x))\n",
    "train_df[\"x_phase_length_max\"]=train_df[\"x_phases_length\"].apply(lambda x:max(x))\n",
    "train_df[\"x_phase_length_25\"]=train_df[\"x_phases_length\"].apply(lambda x:np.percentile(x,25))\n",
    "train_df[\"x_phase_length_50\"]=train_df[\"x_phases_length\"].apply(lambda x:np.percentile(x,50))\n",
    "train_df[\"x_phase_length_75\"]=train_df[\"x_phases_length\"].apply(lambda x:np.percentile(x,75))\n",
    "train_df[\"x_phase_length_mean\"]=train_df[\"x_phases_length\"].apply(lambda x:np.mean(x))\n",
    "train_df[\"x_phase_length_var\"]=train_df[\"x_phases_length\"].apply(lambda x:np.var(x))\n",
    "train_df[\"x_phase_length_count\"]=train_df[\"x_phases_length\"].apply(lambda x:len(x))\n",
    "\n",
    "\n",
    "\n",
    "def f(s):\n",
    "    target_point_x = float(s[\"target_point_x\"])\n",
    "    points_x = s[\"points_x\"]\n",
    "    points_time =s[\"points_time\"]\n",
    "    for i in range(0,len(points_x)):\n",
    "        if (points_x[i]>target_point_x and i>=1):\n",
    "            return (float(points_x[i])-float(points_x[i-1]))/(float(points_time[i])-float(points_time[i-1]))\n",
    "    return 0\n",
    "# target 附近x的速度\n",
    "train_df[\"near_target_x_velocity\"]=train_df[[\"points_time\",\"points_x\",\"target_point_x\"]].apply(f,axis=1)\n",
    "\n",
    "# target 附近x的速度 - 速度最大值\n",
    "train_df[\"near_target_x_velocity_minus_max_velocity\"]= train_df[\"near_target_x_velocity\"]-train_df[\"max_velocity_x\"]\n",
    "# target 附近x的速度 - 速度最小值\n",
    "train_df[\"near_target_x_velocity_minus_min_velocity\"]=train_df[\"near_target_x_velocity\"]-train_df[\"min_velocity_x\"]\n",
    "# target 附近x的速度 - 速度均值\n",
    "train_df[\"near_target_x_velocity_minus_mean_velocity\"]=train_df[\"near_target_x_velocity\"]-train_df[\"velocity_x_mean\"]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import cross_validation, metrics\n",
    "train_x= train_df[[\"points_y_var\",\"points_x_var\",\"velocity_x_mean\",\"velocity_y_mean\",\"accelerate_x_mean\",\"accelerate_y_mean\",\"velocity_x_var\",\"velocity_y_var\",\"accelerate_x_var\",\"accelerate_y_var\",\n",
    "                            \"max_velocity_x\",\"max_velocity_y\",\"max_accelerate_x\",\"max_accelerate_y\",\"min_velocity_x\",\"min_velocity_y\",\"min_accelerate_x\",\"min_accelerate_y\",\"count_velocity\",\"velocity_x_percentile_25\",\n",
    "                           \"velocity_y_percentile_25\", \"accelerate_x_percentile_25\",\"accelerate_y_percentile_25\",\"velocity_x_percentile_75\",\"velocity_y_percentile_75\",\"accelerate_x_percentile_75\",\"accelerate_y_percentile_75\",\n",
    "                            \"velocity_x_percentile_50\",\"velocity_y_percentile_50\",\"accelerate_x_percentile_50\",\"accelerate_y_percentile_50\",\"x_mean_dis_target_x\",\"y_mean_dis_target_y\",\"x_dis_target_point_x_min\",\n",
    "                            \"x_dis_target_point_x_max\",\"x_dis_target_point_x_25\",\"x_dis_target_point_x_50\",\"x_dis_target_point_x_75\",\"x_dis_target_point_x_average\",\"x_dis_target_point_x_var\",\"y_dis_target_point_y_min\",\"y_dis_target_point_y_max\",\n",
    "                            \"y_dis_target_point_y_25\",\"y_dis_target_point_y_50\",\"y_dis_target_point_x_75\",\"y_dis_target_point_y_average\",\"y_dis_target_point_y_var\",\"y_diff_count\",\"x_phase_length_min\",\"x_phase_length_max\",\"x_phase_length_25\",\n",
    "                           \"x_phase_length_50\", \"x_phase_length_75\",\"x_phase_length_mean\",\"x_phase_length_var\",\"x_phase_length_count\",\n",
    "                            \"near_target_x_velocity\",\"near_target_x_velocity_minus_max_velocity\",\"near_target_x_velocity_minus_min_velocity\",\n",
    "                            \"near_target_x_velocity_minus_mean_velocity\"]]\n",
    "train_y =train_df[\"label\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.2)\n",
    "\n",
    "\n",
    " \n",
    "# person_indices=y_train[y_train.label==1].index\n",
    "# robort_indices=y_train[y_train.label==0].index\n",
    "# person_len = len(robort_indices)* 3\n",
    "# person_random_indices = np.random.choice(person_indices, person_len, replace=False)\n",
    "\n",
    "# x_train1 = pd.concat([x_train.loc[person_random_indices], x_train.loc[robort_indices]])\n",
    "# y_train1= pd.concat([ y_train.loc[person_random_indices], y_train.loc[robort_indices]])\n",
    "\n",
    "'''\n",
    "max_depth ：限定了决策树的最大深度，对于防止过拟合非常有用。\n",
    "min_samples_leaf ：限定了叶子节点包含的最小样本数，这个属性对于防止上文讲到的数据碎片问题很有作用。 (因为随着树的深度增加，叶子上的样本数会越来越少)\n",
    "善用min_samples_split和min_samples_leaf参数来控制叶子节点的样本数量，防止overfitting。\n",
    "平衡训练数据中的各个种类的数据，防止被一个种类的数据支配。\n",
    "\n",
    "\n",
    "http://www.cnblogs.com/pinard/p/6160412.html\n",
    "内部节点再划分所需最小样本数min_samples_split: 这个值限制了子树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。 默认是2.如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。\n",
    "\n",
    "叶子节点最少样本数min_samples_leaf: 这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。 默认是1,可以输入最少的样本数的整数，或者最少样本数占样本总数的百分比。如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。\n",
    "'''\n",
    "param1 = {'n_estimators':range(10,81,10),'max_depth':range(1,101,9)}\n",
    "gv = GridSearchCV(estimator = RandomForestClassifier(random_state=10), \n",
    "                       param_grid = param1, scoring='f1',cv=5)\n",
    "gv.fit(x_train,y_train)\n",
    "print  gv.grid_scores_\n",
    "print \"---------\"\n",
    "print gv.best_params_\n",
    "print \"----------\"\n",
    "print gv.best_score_\n",
    "'''\n",
    "{'n_estimators': 40, 'max_depth': 21}\n",
    "----------\n",
    "0.997374774755\n",
    "'''\n",
    "\n",
    "#clf.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=45, max_depth=15,random_state=10,oob_score=True)\n",
    "rf.fit(x_train,y_train)\n",
    "feature_importances = zip(rf.feature_importances_ , [ x for x in range(0,60)])\n",
    "print feature_importances\n",
    "print \"----------------\"\n",
    "def sort_f(x,y):\n",
    "    if (x[0]<y[0]):\n",
    "        return -1\n",
    "    elif (x[0]>y[0]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "sorted_feature_importances= sorted(feature_importances,sort_f)\n",
    "print sorted_feature_importances\n",
    "print \"----------------\"\n",
    "print rf.oob_score_  \n",
    "print \"----------------\"\n",
    "y_predict = rf.predict(x_test)\n",
    "print metrics.f1_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print x_train.columns[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del　x_train[\"velocity_y_percentile_50\"] # 第２８维\n",
    "del    x_train[\"x_dis_target_point_x_25\"]  # 第３５维\n",
    "del    x_train[\"velocity_y_percentile_75\"] # 第２４维\n",
    "del    x_train[\"accelerate_y_percentile_25\"] #第２２维\n",
    "　"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
